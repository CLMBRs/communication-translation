ec:
  model:
    model_name: Output/t2i_en-ne_seed1/t2i_captions_clipL_transformer_from-pretrained
    load_entire_agent: true
    reshaper_type: learned
    two_ffwd: false
    unit_norm: false
    dropout: 0.0
    share_reshaper: true
    image_unroll: transformer
    image_unroll_length: 32
    recurrent_hidden_aggregation: true
    freeze_adapters: false
    freeze_sender: false
    freeze_receiver: false
  train_eval:
    seed: 1
    sender_input_type: text
    language_model_lambda: 0.0625
    language_model_path: ./Output/mbart_lm_lr6e-6
    weight_drift_lambda: 0.0
    do_train: true
    do_eval: false
    n_gpu: 1
    num_games: 30
    max_global_step: 2048
    lr: 1.0e-06
    schedule: linear_w_warmup
    num_warmup_steps: 0
    batch_size: 12
    gradient_accumulation_steps: 1
    grad_clip: 0.5
    valid_every: 256
    max_eval_batches: 64
    print_every: 32
    target_acc: 85.0
    stats_to_print:
    - loss
    - accuracy
    - lm loss
    - drift loss
    - communication loss
    - mean_length
    num_distractors_train: 15
    num_distractors_valid: 15
  generation:
    beam_width: 1
    temperature: 1.0
    hard: true
    repetition_penalty: 1.2
    generate_from_logits: false
    max_seq_length: 32
    TransferH: false
    max_text_seq_length: 128
  data:
    base_dir: ./DataLink/ec_finetuning_new
    train_captions: ${.base_dir}/en_captions_train.jsonl
    valid_captions: ${.base_dir}/en_captions_val.jsonl
    train_images: ${.base_dir}/clipL_train.pt
    valid_images: ${.base_dir}/clipL_val.pt
    image_dim: 768
    save_output_txt: true
  language:
    has_vocab_constraint: true
    vocab_constraint_threshold: 0.96
    source_lang: en_XX
    source_lang_vocab_constrain_file: ./Data/cc/en_cc_tokenID2count_dict.cc25.json
    target_lang: ne_NP
    target_lang_vocab_constrain_file: ./Data/cc/ne_cc_tokenID2count_dict.facebook-mbart-large-cc25.json
  output_dir: Output/t2i_en-ne_seed1/t2i_ec_clipL_transformer_from-pretrained
  mode: emergent_communication
  save_pretrain_seperately: true
