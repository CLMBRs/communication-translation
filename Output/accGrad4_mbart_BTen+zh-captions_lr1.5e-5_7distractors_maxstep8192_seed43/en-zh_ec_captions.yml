# Model:
model_name: Models/bt_en-zh_captions
image_dim: 2048
hidden_dim: 512
bidirectional: false # RNN-specific
num_layers: 1 # RNN-specific
vocab_size: 4035 # RNN-specific
two_ffwd: false
unit_norm: false
dropout: 0.1
fix_bhd: false
fix_spk: false
no_share_bhd: false

# Generation
decode_how: beam
beam_width: 5
temperature: 1.0
temp: 1.0
hard: false
max_seq_length: 64
TransferH: false #switch to hard gumbel after the model reaches target accuracy.

# Train and eval:
seed: 43
mode: emergent_communication
do_train: true # true # control whether we train
do_eval: true # whether to do eval after training
n_gpu: 1
cpu: false
num_games: 30 # Upper bound of the num of epochs
max_global_step: 8192
lr: 1.5e-5
batch_size: 8
gradient_accumulation_steps: 4
grad_clip: 1.0
no_terminal: false
no_write: false
valid_every: 512
print_every: 10
target_acc: 85.0
stats_to_print: ['loss', 'accuracy', 'caption generation loss', 'image selection loss', 'mean_length']

# Number of image distractors
num_distractors_train: 7
num_distractors_valid: 7

# Loading and saving data:
# train_captions: ./Data/Coco/captioning/en_train_captions.jsonl
# valid_captions: ./Data/Coco/captioning/en_valid_captions.jsonl
train_images: ./Data/ec_finetuning/images_train
valid_images: ./Data/ec_finetuning/images_val
save_pretrain_seperately: true
# good practice: set the output_dir name the same as the parameter file name
output_dir: Output/accGrad4_mbart_BTen+zh-captions_lr1.5e-5_7distractors_maxstep8192_seed43
save_output_txt: true

# Other (we may choose to delete these later):
alpha: 1.0

# Specify info about language and vocab constraint
has_vocab_constraint: false
source_lang: en_XX
source_lang_vocab_constrain_file: /projects/unmt/communication-translation/en_cc_tokenID2count_dict.cc25.json
target_lang: zh_CN
target_lang_vocab_constrain_file: /projects/unmt/communication-translation/zh-Hans_cc_tokenID2count_dict.cc25.json
