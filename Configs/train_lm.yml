model_name: facebook/mbart-large-cc25
seed: 1
output_dir: Output/mbart_lm_lr6e-6
csv_headers: ['mode', 'epoch', 'global step', 'lr', 'loss']
data_dir: DataLink/cc
train_data_files:
  en: en_tail_train.txt
  zh: zh_tail_train.txt
  de: de_tail_train.txt
  ro: ro_tail_train.txt
  ne: ne_tail_train.txt
  si: si_tail_train.txt
valid_data_files:
  en: en_tail_val.txt
  zh: zh_tail_val.txt
  de: de_tail_val.txt
  ro: ro_tail_val.txt
  ne: ne_tail_val.txt
  si: si_tail_val.txt
lang_alpha: 1.0

do_train: true
do_eval: true
n_gpu: 1
max_global_step: 100000
num_epochs: 1
lr: 6.0e-6
schedule: linear_w_warmup
num_warmup_steps: 0
max_seq_length: 96
batch_size: 32
gradient_accumulation_steps: 1
grad_clip: 0.5
valid_every: 5000
print_every: 250
