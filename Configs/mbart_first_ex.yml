# Model:
model_name: mbart
#bart: true
beam_width: 12
cpu: True
decode_how: beam
dropout: 0.1
eval_mode: false
embedding_dim: 1024
hidden_dim: 512
image_dim: 2048
bidirectional: false # RNN-specific
num_layers: 1 #RNN-specific
vocab_size: 4035 #RNN-specific
fix_bhd: false
fix_spk: false
no_share_bhd: false

# Train and eval:
# train eval basic setting
do_train: true # control whether we train
do_eval: true # whether to do eval after training
seed: 42
n_gpu: 1
cpu: False
# training parameters
dropout: 0.1
grad_clip: 1.0
hard: true # Gumbel softmax sampling; we always prefer to set this true
seq_len: 15 # sequence length limit
temp: 1.0 # temperature for gumbel softmax
loss_type: xent
lr: 5.0e-7
no_share_bhd: false
no_terminal: false
no_write: false
norm_pow: 0.0
target_acc: 85.0

# Total number of pictures for listeners, the first one is for training. 
# gaming logistics
num_games: 30 # Upper bound of the num of epochs
max_global_step: 30000
num_distractors_train: 3
num_distractors_valid: 3
num_games: 30000
num_layers: 1
pretrain_spk: false
print_every: 50
re_load: false
sample_how: gumbel
save_every: 4000
seq_len: 15
stop_after: 30
temperature: 1.0
translate_every: 2000
two_ffwd: false
unit_norm: false
batch_size: 64
valid_batch_size: 128
valid_every: 500
print_every: 50
TransferH: false #switch to hard gumbel after the model reaches target accuracy.

# Loading and saving data:
dataset: coco
coco_path: ./UMT_data/coco_new
save_pretrain_seperately: true
# good practice: set the output_dir name the same as the parameter file name
output_dir: mbart_first_ex 
save_output_txt: true

# Other (we may choose to delete these later):

# Other (we may choose to delete these later):
alpha: 1.0
beam_width: 12
decode_how: beam
no_terminal: false # This parameter isn't used anywhere
no_write: false
norm_pow: 0.0 # for MT part, not relevant here.
sample_how: gumbel # we always use gumbel in our case


# specify info about language and vocab constraint
has_vocab_constraint: false
source_lang: en_XX
source_lang_vocab_constrain_file: ./Data/cc/en_europarl_count_dict.json
target_lang: ja_XX
target_lang_vocab_constrain_file: ./Data/cc/ja_smaller_count_dict.json
