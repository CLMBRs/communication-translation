model_path: Output/mbart_wcons/model.pt
args_path: Output/mbart_wcons/training_args.bin

# training config
lr: 1.0e-05
batch_size: 2
seed: 42
n_gpu: 0
print_every: 2
num_steps: 1000
# dir to save model from lang1 to lang2
output_dir: Output/bt_en+ja/
# dir to save model from lang2 to lang1

# data config
data_dir: ./Data/BackTranslate
lang1_data_file: en/en_head100.txt
lang1_id: ja
lang1_vocab_constrain_file: ./Data/cc/en_europarl_count_dict.json

lang2_data_file: ja/ja_1_head100.txt
lang2_id: en
lang2_vocab_constrain_file: ./Data/cc/ja_smaller_count_dict.json

# backtranslation language
models_shared: true
